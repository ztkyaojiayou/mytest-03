spring:
  application:
    name: model-dp
  datasource:
    platform: postgres
    url: jdbc:postgresql://192.188.1.245:5432/newdb?currentSchema=model
    schemaName: model
    username: smartsys
    password: smartsys
    driver-class-name: org.postgresql.Driver
  influxdb:
    url: http://192.188.1.245:8086/
    user: admin
    password: sf@123456
    database: sf-bucket
    token: "ItXo5mJLdi45dBEaJapeLi7eK5W1rDZK3VKdKrqHJlyTS5rBWPlP9lY2KrrVCpm1oC9NXX-SJBHLLAiSLuDhzw=="
  redis:
    cluster:
      nodes:
        - 192.188.1.244:6379
        - 192.188.1.245:6379
        - 192.188.1.246:6379
      connectionTimeout: 3000 #连接超时时间
      soTimeout: 1000 #数据超时时间
      max-redirects: 3 #最大重连次数
      max-Attempt: 3 #最大尝试次数
    database: 0 #默认链接数据库
    host: 192.188.1.245  # Redis服务器地址
    port: 6379  # Redis服务器连接端口
    password: "sf@123456"  # Redis服务器连接密码（默认为空）
    pool:
      max-active: 8  # 连接池最大连接数（使用负值表示没有限制）
      max-wait: -1  # 连接池最大阻塞等待时间（使用负值表示没有限制）
      max-idle: 8  # 连接池中的最大空闲连接
      min-idle: 0  # 连接池中的最小空闲连接
    timeout: 3000  # 连接超时时间（毫秒）

  kafka:
    listener:
      #设置是否批量消费，默认 single（单条），batch（批量）
      type: batch
      # 消费端监听的topic不存在时，项目启动会报错(关掉)
      missing-topics-fatal: false
    # 集群地址
    bootstrap-servers: 192.188.1.245:9092
    # 消费者配置
    consumer:
      # 默认消费者组
      group-id: testGroup
      # 自动提交 offset 默认 true
      enable-auto-commit: true
      # 自动提交的频率 单位 ms
      auto-commit-interval: 1000
      # 批量消费最大数量
      max-poll-records: 100
      # Key 反序列化类
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      # Value 反序列化类
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      # 当kafka中没有初始offset或offset超出范围时将自动重置offset
      # earliest:重置为分区中最小的offset
      # latest:重置为分区中最新的offset(消费分区中新产生的数据)
      # none:只要有一个分区不存在已提交的offset,就抛出异常
      auto-offset-reset: latest

mybatis-plus:
  mapper-locations: classpath:/mapper/*Mapper.xml
  #实体扫描，多个package用逗号或者分号分隔
  typeAliasesPackage: com.sfauto.cloud.model
  global-config:
    db-config:
      id-type: auto
      select-strategy: not_empty
  configuration:
    use-generated-keys: true

csgc:
  kafka:
    topics:
      ptyc: point_yc